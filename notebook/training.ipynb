{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "prqt = pd.read_parquet('../data/parquet/MultL/test_multilingual.parquet', engine='fastparquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "prqt_pt = prqt[prqt['lang'] == 'pt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def map_tag(tag_id):\n",
        "    if tag_id in range(1, 3):\n",
        "        return \"PER\"\n",
        "    elif tag_id in range(3, 5):\n",
        "        return \"ORG\"\n",
        "    elif tag_id in range(5, 7):\n",
        "        return \"LOC\"\n",
        "    elif tag_id in range(7, 9):\n",
        "        return \"MIST\"\n",
        "    else:\n",
        "        return \"O\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_tokens_to_spacy_format(tokens, tags):\n",
        "    text = \"\"\n",
        "    entities = []\n",
        "    token_start = 0\n",
        "\n",
        "    for i, (token, tag_id) in enumerate(zip(tokens, tags)):\n",
        "        tag = map_tag(tag_id)\n",
        "\n",
        "        # Calcula os offsets\n",
        "        start = len(text)\n",
        "        text += token\n",
        "        end = len(text)\n",
        "\n",
        "        if i < len(tokens) - 1:\n",
        "            text += \" \"\n",
        "\n",
        "        if tag != \"O\":\n",
        "            # Se for entidade, adiciona aos spans\n",
        "            entities.append((start, end, tag))\n",
        "\n",
        "    return (text.strip(), {\"entities\": entities})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Por volta de 1874 , a sede do governo do condado foi transferida de Mineola para Long Island City .', {'entities': [(68, 75, 'LOC'), (81, 85, 'LOC'), (86, 92, 'LOC'), (93, 97, 'LOC')]})\n",
            "('Na população nascida no exterior , 49,5 % nasceram na América Latina , 33,5 % na Ásia , 14,8 % na Europa , 1,8 % na África e 0,4 % na América do Norte .', {'entities': [(54, 61, 'LOC'), (62, 68, 'LOC'), (81, 85, 'LOC'), (98, 104, 'LOC'), (116, 122, 'LOC'), (134, 141, 'LOC'), (142, 144, 'LOC'), (145, 150, 'LOC')]})\n",
            "('Além disso , 51,2 % da população nasceu nos Estados Unidos .', {'entities': [(44, 51, 'LOC'), (52, 58, 'LOC')]})\n",
            "('A partir da sede na Suíça a entidade se tornou uma rede mundial de defesa do meio ambiente , com representações nos principais países do mundo .', {'entities': [(20, 25, 'LOC')]})\n",
            "('Em 2014 , citando condições desatualizadas nos terminais do aeroporto , o vice-presidente Joe Biden comparou o Aeroporto LaGuardia a \" país de terceiro mundo \" .', {'entities': [(90, 93, 'PER'), (94, 99, 'PER'), (111, 120, 'LOC'), (121, 130, 'LOC')]})\n"
          ]
        }
      ],
      "source": [
        "data_spacy = [\n",
        "    convert_tokens_to_spacy_format(row[\"tokens\"], row[\"ner_tags\"])\n",
        "    for _, row in prqt_pt.iterrows()\n",
        "]\n",
        "\n",
        "for item in data_spacy[:5]:\n",
        "    print(item)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_DATA = data_spacy[:int(len(data_spacy) * 0.90)]\n",
        "DEV_DATA = data_spacy[:int(len(data_spacy) * 0.10)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_docbin(data, file_path):\n",
        "    nlp = spacy.blank(\"pt\")\n",
        "    db = DocBin()\n",
        "\n",
        "    print(f\"Gerando dados para {file_path}...\")\n",
        "    for text, annot in tqdm(data):\n",
        "        doc = nlp.make_doc(text)\n",
        "        ents = []\n",
        "        for start, end, label in annot[\"entities\"]:\n",
        "            span = doc.char_span(start, end, label=label)\n",
        "            if span is not None:\n",
        "                ents.append(span)\n",
        "        doc.ents = ents\n",
        "        db.add(doc)\n",
        "\n",
        "    db.to_disk(file_path)\n",
        "    print(f\"Dados salvos em '{file_path}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\Desktop\\git\\codigos\\faculdade\\bigdata-tmp\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gerando dados para ../train.spacy...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9144/9144 [00:00<00:00, 10204.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dados salvos em '../train.spacy'\n",
            "Gerando dados para ../dev.spacy...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1016/1016 [00:00<00:00, 7784.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dados salvos em '../dev.spacy'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "create_docbin(TRAIN_DATA, \"../train.spacy\")\n",
        "create_docbin(DEV_DATA, \"../dev.spacy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI ORG\n",
            "João PER\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "# C:/Users/mathe/OneDrive/Desktop/git/codigos/faculdade/bigdata-tmp/model-1/model-best\n",
        "nlp = spacy.load(\"C:/Users/mathe/OneDrive/Desktop/git/codigos/faculdade/bigdata-tmp/model-1/model-best\")\n",
        "\n",
        "doc = nlp(\"A OpenAI é uma empresa maravilhosa que o João trabalha\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m spacy train ./config.cfg --output ./model --paths.train ./traning/train_data.spacy --paths.dev ./traning/dev_data.spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m spacy train config_trf.cfg --paths.train train.spacy --paths.dev dev.spacy --gpu-id 0 -o training"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
