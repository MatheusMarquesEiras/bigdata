{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0038943b",
   "metadata": {},
   "source": [
    "# ARQUIVO DE CONFIG EFFICIENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54511fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: pt\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "..\\config\\config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init config ../config/config.cfg \\\n",
    "    --lang pt \\\n",
    "    --pipeline tok2vec,ner \\\n",
    "    --optimize efficiency \\\n",
    "    --force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946d239d",
   "metadata": {},
   "source": [
    "# ARQUIVO DE CONFIG ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826780b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: pt\n",
      "- Pipeline: ner\n",
      "- Optimize for: accuracy\n",
      "- Hardware: GPU\n",
      "- Transformer: neuralmind/bert-base-portuguese-cased\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "..\\config\\config_trf.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_trf.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init config \\\n",
    "    ../config/config_trf.cfg \\\n",
    "    --lang pt \\\n",
    "    --pipeline transformer,ner \\\n",
    "    --optimize accuracy \\\n",
    "    --force \\\n",
    "    --gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43468f7",
   "metadata": {},
   "source": [
    "# INICIAR TREINAMENTO EFFICIENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5a50fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created output directory: ..\\models\\model_tok2vec\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving to output directory: ..\\models\\model_tok2vec\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     53.83    0.00    0.00    0.00    0.00\n",
      "  0     200         50.46   2648.45   61.24   62.27   60.24    0.61\n",
      "  0     400         89.97   1581.68   73.24   73.11   73.36    0.73\n",
      "  0     600        145.26   1762.00   78.61   79.95   77.31    0.79\n",
      "  0     800        163.20   1703.79   81.14   80.35   81.96    0.81\n",
      "  0    1000        209.20   1819.34   84.77   84.97   84.57    0.85\n",
      "  0    1200        249.69   2131.48   85.52   85.85   85.19    0.86\n",
      "  0    1400        291.66   2326.95   86.95   87.59   86.32    0.87\n",
      "  0    1600        561.15   2796.48   89.10   89.27   88.92    0.89\n",
      "  0    1800        454.99   2902.65   90.04   89.85   90.23    0.90\n",
      "  0    2000        695.83   3182.35   91.15   91.10   91.21    0.91\n",
      "  0    2200        599.01   3472.64   91.84   91.69   91.98    0.92\n",
      "  0    2400        742.39   3893.61   92.32   92.24   92.40    0.92\n",
      "  0    2600        720.66   3706.73   93.30   93.36   93.24    0.93\n",
      "  0    2800        771.69   3687.93   93.40   93.29   93.50    0.93\n",
      "  0    3000        715.39   3231.35   94.27   94.02   94.51    0.94\n",
      "  0    3200        752.92   3283.48   94.57   94.33   94.80    0.95\n",
      "  0    3400        775.01   3240.70   94.79   94.62   94.97    0.95\n",
      "  0    3600        769.84   2938.25   95.00   95.12   94.89    0.95\n",
      "  0    3800        710.94   2744.35   95.25   95.16   95.34    0.95\n",
      "  0    4000        731.21   2722.49   95.58   95.43   95.73    0.96\n",
      "  0    4200        733.83   2534.20   95.52   95.09   95.95    0.96\n",
      "  0    4400        749.36   2573.75   95.84   95.64   96.03    0.96\n",
      "  0    4600        714.75   2502.85   96.26   96.26   96.26    0.96\n",
      "  0    4800        726.08   2498.05   96.15   96.05   96.25    0.96\n",
      "  0    5000        767.27   2529.59   96.24   96.05   96.42    0.96\n",
      "  0    5200        742.66   2268.70   96.52   96.64   96.39    0.97\n",
      "  0    5400        699.40   2125.18   96.61   96.64   96.57    0.97\n",
      "  0    5600        716.04   2120.29   96.80   96.93   96.66    0.97\n",
      "  0    5800        682.83   2019.52   96.86   96.99   96.73    0.97\n",
      "  0    6000        765.52   2088.79   96.73   96.75   96.70    0.97\n",
      "  0    6200        686.30   1766.57   96.96   96.90   97.02    0.97\n",
      "  0    6400        728.60   1934.35   97.03   97.16   96.91    0.97\n",
      "  0    6600        727.39   1933.70   97.12   97.00   97.23    0.97\n",
      "  0    6800        750.18   1721.07   97.29   97.13   97.44    0.97\n",
      "  1    7000        710.09   1452.80   97.30   97.34   97.25    0.97\n",
      "  1    7200        685.38   1437.99   97.44   97.60   97.28    0.97\n",
      "  1    7400        707.04   1383.09   97.38   97.60   97.15    0.97\n",
      "  1    7600        704.68   1435.47   97.51   97.27   97.74    0.98\n",
      "  1    7800        686.18   1293.22   97.69   97.70   97.68    0.98\n",
      "  1    8000        688.55   1391.21   97.72   97.86   97.58    0.98\n",
      "  1    8200        734.90   1406.09   97.69   97.77   97.60    0.98\n",
      "  1    8400        739.51   1451.91   97.80   97.77   97.83    0.98\n",
      "  1    8600        727.34   1350.83   97.59   97.43   97.75    0.98\n",
      "  1    8800        693.68   1323.03   97.82   97.77   97.86    0.98\n",
      "  1    9000        706.91   1363.20   97.82   97.62   98.02    0.98\n",
      "  1    9200        659.03   1233.04   97.97   97.95   98.00    0.98\n",
      "  1    9400        733.63   1278.49   97.90   97.65   98.16    0.98\n",
      "  1    9600        700.12   1306.01   98.05   97.98   98.11    0.98\n",
      "  1    9800        731.24   1263.98   98.17   98.22   98.11    0.98\n",
      "  1   10000        732.08   1281.18   98.09   98.11   98.07    0.98\n",
      "  1   10200        733.97   1282.37   98.04   97.91   98.17    0.98\n",
      "  1   10400        742.38   1247.44   98.17   98.32   98.01    0.98\n",
      "  1   10600        749.58   1255.96   98.24   98.09   98.40    0.98\n",
      "  1   10800        788.38   1147.10   98.14   98.14   98.14    0.98\n",
      "  1   11000        794.85   1204.52   98.27   98.06   98.48    0.98\n",
      "  1   11200        805.14   1185.66   98.30   98.16   98.43    0.98\n",
      "  1   11400        823.54   1176.98   98.20   98.26   98.13    0.98\n",
      "  1   11600        746.34   1110.80   98.36   98.47   98.26    0.98\n",
      "  1   11800        765.61   1199.82   98.43   98.31   98.55    0.98\n",
      "  1   12000        690.61   1073.52   98.41   98.33   98.49    0.98\n",
      "  1   12200        736.09   1069.77   98.46   98.44   98.48    0.98\n",
      "  2   12400        750.36    884.61   98.43   98.35   98.50    0.98\n",
      "  2   12600        751.00    835.89   98.51   98.51   98.52    0.99\n",
      "  2   12800        759.41    853.13   98.44   98.49   98.40    0.98\n",
      "  2   13000        772.80    934.12   98.39   98.22   98.55    0.98\n",
      "  2   13200        753.82    936.90   98.51   98.34   98.68    0.99\n",
      "  2   13400        782.28    960.61   98.50   98.42   98.58    0.99\n",
      "  2   13600        759.02    862.03   98.61   98.66   98.56    0.99\n",
      "  2   13800        924.20    904.06   98.53   98.30   98.76    0.99\n",
      "  2   14000        771.07    857.16   98.66   98.76   98.55    0.99\n",
      "  2   14200        822.25    913.09   98.67   98.60   98.75    0.99\n",
      "  2   14400        877.08   1006.20   98.66   98.57   98.75    0.99\n",
      "  2   14600        858.54    951.30   98.63   98.59   98.68    0.99\n",
      "  2   14800        855.27    911.56   98.77   98.68   98.86    0.99\n",
      "  2   15000        784.93    884.90   98.71   98.64   98.77    0.99\n",
      "  2   15200        836.08    819.56   98.81   98.80   98.81    0.99\n",
      "  2   15400        881.78    883.62   98.80   98.89   98.71    0.99\n",
      "  2   15600        880.74    929.76   98.85   98.84   98.86    0.99\n",
      "  2   15800        825.10    840.79   98.81   98.82   98.80    0.99\n",
      "  2   16000        843.69    749.82   98.87   98.86   98.88    0.99\n",
      "  2   16200        857.67    820.54   98.76   98.84   98.68    0.99\n",
      "  2   16400        933.92    889.38   98.81   98.73   98.90    0.99\n",
      "  2   16600        834.81    820.58   98.86   98.80   98.93    0.99\n",
      "  2   16800        860.78    798.31   98.78   98.77   98.80    0.99\n",
      "  2   17000        924.00    814.42   98.89   98.83   98.95    0.99\n",
      "  2   17200        868.99    840.48   98.95   98.83   99.06    0.99\n",
      "  2   17400        890.95    808.30   99.07   99.07   99.07    0.99\n",
      "  2   17600        883.34    799.20   99.03   98.98   99.08    0.99\n",
      "  3   17800        797.05    614.61   99.04   99.01   99.07    0.99\n",
      "  3   18000        998.64    713.43   98.97   98.95   98.98    0.99\n",
      "  3   18200        960.20    647.37   98.90   98.86   98.93    0.99\n",
      "  3   18400        986.22    669.56   98.99   99.02   98.96    0.99\n",
      "  3   18600       1021.35    681.53   98.99   99.05   98.92    0.99\n",
      "  3   18800        991.86    633.09   98.90   98.73   99.08    0.99\n",
      "  3   19000       1275.42    796.23   98.90   98.86   98.94    0.99\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "..\\models\\model_tok2vec\\model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train ../config/config.cfg \\\n",
    "  --output ../models/model_tok2vec \\\n",
    "  --paths.train ../spacy/train.spacy \\\n",
    "  --paths.dev ../spacy/dev.spacy \\\n",
    "  --gpu-id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8e7f78",
   "metadata": {},
   "source": [
    "# INICIAR TREINAMENTO ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f7ae01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created output directory: ..\\models\\model_trf_gpu\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving to output directory: ..\\models\\model_trf_gpu\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  -------------  --------  ------  ------  ------  ------\n",
      "  0       0         121.50    152.58    9.75    5.53   41.18    0.10\n",
      "  0     200       49827.79  60983.08   95.72   95.75   95.69    0.96\n",
      "  0     400        1560.82   2973.91   96.29   96.24   96.35    0.96\n",
      "  0     600        1236.06   2388.34   96.68   96.20   97.16    0.97\n",
      "  0     800        1135.93   2145.74   97.21   97.10   97.31    0.97\n",
      "  0    1000        1010.59   1910.90   97.47   97.53   97.41    0.97\n",
      "  0    1200         994.74   1907.21   97.77   97.82   97.71    0.98\n",
      "  0    1400         823.05   1622.11   97.89   98.14   97.65    0.98\n",
      "  0    1600         814.01   1576.75   98.01   97.87   98.15    0.98\n",
      "  0    1800         698.25   1361.97   98.10   97.94   98.26    0.98\n",
      "  0    2000         728.35   1416.09   98.34   98.34   98.34    0.98\n",
      "  0    2200         695.90   1351.04   98.42   98.29   98.55    0.98\n",
      "  0    2400         709.96   1356.32   98.56   98.62   98.51    0.99\n",
      "  0    2600         628.17   1229.67   98.54   98.57   98.52    0.99\n",
      "  0    2800         583.62   1145.77   98.67   98.45   98.88    0.99\n",
      "  0    3000         520.94   1074.87   98.82   98.81   98.83    0.99\n",
      "  0    3200         467.50    947.21   98.76   98.77   98.75    0.99\n",
      "  0    3400         466.37    892.79   98.85   98.83   98.88    0.99\n",
      "  0    3600         500.32    942.13   98.90   98.77   99.02    0.99\n",
      "  1    3800         381.56    721.98   99.02   99.11   98.93    0.99\n",
      "  1    4000         297.88    595.51   99.00   98.98   99.03    0.99\n",
      "  1    4200         312.08    586.44   99.06   99.00   99.13    0.99\n",
      "  1    4400         294.77    567.66   99.07   99.04   99.10    0.99\n",
      "  1    4600         274.05    513.39   99.07   99.04   99.10    0.99\n",
      "  1    4800         309.99    555.29   99.07   99.02   99.12    0.99\n",
      "  1    5000         288.63    522.48   99.16   99.15   99.18    0.99\n",
      "  1    5200         356.54    622.45   99.09   99.04   99.13    0.99\n",
      "  1    5400         283.71    518.83   99.28   99.31   99.26    0.99\n",
      "  1    5600         297.63    543.26   99.30   99.27   99.33    0.99\n",
      "  1    5800         302.46    512.73   99.34   99.25   99.42    0.99\n",
      "  1    6000         272.74    472.31   99.34   99.21   99.46    0.99\n",
      "  1    6200         231.53    431.41   99.40   99.33   99.47    0.99\n",
      "  1    6400         284.42    486.77   99.41   99.34   99.48    0.99\n",
      "  1    6600         214.93    363.11   99.35   99.17   99.54    0.99\n",
      "  1    6800         254.08    422.09   99.47   99.44   99.50    0.99\n",
      "  1    7000         255.18    420.90   99.50   99.57   99.44    1.00\n",
      "  1    7200         223.99    347.44   99.50   99.46   99.55    1.00\n",
      "  1    7400         273.70    433.11   99.54   99.49   99.58    1.00\n",
      "  2    7600         178.65    298.85   99.54   99.51   99.57    1.00\n",
      "  2    7800         122.98    186.83   99.57   99.57   99.56    1.00\n",
      "  2    8000         127.84    225.46   99.55   99.53   99.58    1.00\n",
      "  2    8200         183.78    276.79   99.61   99.57   99.65    1.00\n",
      "  2    8400         176.74    271.16   99.63   99.63   99.64    1.00\n",
      "  2    8600         156.30    240.76   99.59   99.53   99.66    1.00\n",
      "  2    8800         172.76    235.02   99.65   99.61   99.69    1.00\n",
      "  2    9000         207.97    289.41   99.67   99.61   99.73    1.00\n",
      "  2    9200         155.97    226.32   99.69   99.62   99.75    1.00\n",
      "  2    9400         175.36    246.85   99.64   99.62   99.65    1.00\n",
      "  2    9600         134.32    196.53   99.71   99.68   99.74    1.00\n",
      "  2    9800         174.42    214.70   99.70   99.66   99.75    1.00\n",
      "  2   10000         147.01    215.09   99.72   99.67   99.77    1.00\n",
      "  2   10200         150.92    193.05   99.70   99.62   99.79    1.00\n",
      "  2   10400         159.61    195.79   99.73   99.68   99.79    1.00\n",
      "  2   10600         115.24    165.20   99.77   99.72   99.83    1.00\n",
      "  2   10800         114.92    143.36   99.77   99.72   99.81    1.00\n",
      "  2   11000         138.65    192.51   99.79   99.75   99.84    1.00\n",
      "  3   11200         137.36    164.99   99.76   99.74   99.77    1.00\n",
      "  3   11400          74.66    104.72   99.80   99.76   99.84    1.00\n",
      "  3   11600          83.92    114.66   99.83   99.79   99.87    1.00\n",
      "  3   11800          86.44    113.25   99.81   99.75   99.87    1.00\n",
      "  3   12000          69.73    100.72   99.82   99.78   99.86    1.00\n",
      "  3   12200          66.88     88.49   99.82   99.76   99.88    1.00\n",
      "  3   12400          97.54    127.20   99.84   99.79   99.89    1.00\n",
      "  3   12600          63.69     85.82   99.84   99.79   99.90    1.00\n",
      "  3   12800         115.98    127.43   99.88   99.84   99.92    1.00\n",
      "  3   13000          93.87    128.38   99.87   99.82   99.91    1.00\n",
      "  3   13200          92.15    115.96   99.88   99.85   99.92    1.00\n",
      "  3   13400          72.94     85.37   99.88   99.85   99.91    1.00\n",
      "  3   13600          73.68     95.37   99.89   99.85   99.93    1.00\n",
      "  3   13800          59.10     64.42   99.89   99.86   99.91    1.00\n",
      "  3   14000          36.85     58.39   99.88   99.85   99.91    1.00\n",
      "  3   14200          34.22     58.88   99.88   99.86   99.91    1.00\n",
      "  3   14400          65.16     68.85   99.87   99.83   99.92    1.00\n",
      "  3   14600          63.52     97.65   99.90   99.88   99.92    1.00\n",
      "  3   14800          59.45     74.69   99.89   99.86   99.92    1.00\n",
      "  4   15000          51.79     66.45   99.90   99.87   99.93    1.00\n",
      "  4   15200          54.95     57.69   99.90   99.87   99.93    1.00\n",
      "  4   15400          67.59     81.14   99.89   99.86   99.92    1.00\n",
      "  4   15600          34.75     61.47   99.91   99.88   99.93    1.00\n",
      "  4   15800          72.46     89.92   99.90   99.87   99.94    1.00\n",
      "  4   16000          30.11     43.44   99.92   99.89   99.95    1.00\n",
      "  4   16200          58.00     55.47   99.92   99.88   99.95    1.00\n",
      "  4   16400          28.16     39.19   99.92   99.90   99.95    1.00\n",
      "  4   16600          36.55     56.15   99.93   99.90   99.96    1.00\n",
      "  4   16800          34.70     51.88   99.92   99.89   99.95    1.00\n",
      "  4   17000          41.19     38.81   99.93   99.89   99.97    1.00\n",
      "  4   17200          19.81     20.91   99.93   99.89   99.97    1.00\n",
      "  4   17400          74.50     55.04   99.93   99.89   99.98    1.00\n",
      "  4   17600          31.89     56.35   99.95   99.91   99.98    1.00\n",
      "  4   17800          17.66     47.02   99.94   99.91   99.98    1.00\n",
      "  4   18000          24.11     39.41   99.95   99.91   99.98    1.00\n",
      "  4   18200           7.10     21.13   99.95   99.91   99.98    1.00\n",
      "  4   18400          24.17     46.83   99.95   99.92   99.98    1.00\n",
      "  5   18600          17.42     32.10   99.95   99.92   99.99    1.00\n",
      "  5   18800          26.80     37.53   99.95   99.92   99.99    1.00\n",
      "  5   19000          28.20     35.77   99.96   99.92   99.99    1.00\n",
      "  5   19200          16.07     36.44   99.96   99.92   99.99    1.00\n",
      "  5   19400          14.79     33.39   99.96   99.92   99.99    1.00\n",
      "  5   19600           5.45     19.52   99.96   99.92   99.99    1.00\n",
      "  5   19800           4.56     16.89   99.96   99.92   99.99    1.00\n",
      "  5   20000          11.10     27.51   99.96   99.92   99.99    1.00\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "..\\models\\model_trf_gpu\\model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train ../config/config_trf.cfg \\\n",
    "  --output ../models/model_trf_gpu \\\n",
    "  --paths.train ../spacy/train.spacy \\\n",
    "  --paths.dev ../spacy/dev.spacy \\\n",
    "  --gpu-id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecd8871",
   "metadata": {},
   "source": [
    "# Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03b1d2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: True\n",
      "OpenAi MIST\n",
      "João PER\n",
      "Microsoft ORG\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "print(f'GPU: {spacy.prefer_gpu()}')\n",
    "\n",
    "nlp = spacy.load(\"../models/model_trf_gpu/model-best\")\n",
    "doc = nlp(\"A OpenAi é uma empresa que o João trabalha a Microsoft\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72b52ff",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "- tempo treinamento tok2vec => 36 min 34.4 segundos \n",
    "- tempo treinamento transformers => 130 min 19.4 segundos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
