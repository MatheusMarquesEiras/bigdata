{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0476fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2c5e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_typs = ['dev', 'test', 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fcb8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_conll(arquivo):\n",
    "    tokens_list = []\n",
    "    tags_list = []\n",
    "    \n",
    "    tokens_sent = []\n",
    "    tags_sent = []\n",
    "    \n",
    "    with open(arquivo, 'r', encoding='utf-8') as f:\n",
    "        for linha in f:\n",
    "            linha = linha.strip()\n",
    "            \n",
    "            if linha == \"\":\n",
    "                if tokens_sent:\n",
    "                    tokens_list.append(tokens_sent)\n",
    "                    tags_list.append(tags_sent)\n",
    "                    tokens_sent = []\n",
    "                    tags_sent = []\n",
    "                continue\n",
    "            \n",
    "            partes = linha.split()\n",
    "            if len(partes) >= 2:\n",
    "                token = partes[0]\n",
    "                tag = partes[1]\n",
    "                \n",
    "                tokens_sent.append(token)\n",
    "                tags_sent.append(tag)\n",
    "    \n",
    "    if tokens_sent:\n",
    "        tokens_list.append(tokens_sent)\n",
    "        tags_list.append(tags_sent)\n",
    "    \n",
    "    return tokens_list, tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01be6d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_para_numeros(tags_list):\n",
    "    tags_unicos = set()\n",
    "    for sent in tags_list:\n",
    "        tags_unicos.update(sent)\n",
    "    \n",
    "    tag2id = {tag: i for i, tag in enumerate(sorted(tags_unicos))}\n",
    "    \n",
    "    tags_ids = []\n",
    "    for sent in tags_list:\n",
    "        ids = [tag2id[tag] for tag in sent]\n",
    "        tags_ids.append(ids)\n",
    "    \n",
    "    print(\"Mapeamento de tags:\")\n",
    "    for tag, id_num in sorted(tag2id.items()):\n",
    "        print(f\"  {tag} → {id_num}\")\n",
    "    \n",
    "    return tags_ids, tag2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7972f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_parquet(tokens_list, tags_ids, arquivo_saida):\n",
    "\n",
    "    tokens_array = pa.array(tokens_list, type=pa.list_(pa.utf8()))\n",
    "    tags_array = pa.array(tags_ids, type=pa.list_(pa.int32()))\n",
    "    \n",
    "    table = pa.Table.from_arrays(\n",
    "        [tokens_array, tags_array],\n",
    "        names=[\"tokens\", \"ner_tags\"]\n",
    "    )\n",
    "    \n",
    "    pq.write_table(table, arquivo_saida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27df59c0",
   "metadata": {},
   "source": [
    "# HAREM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a9990ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapeamento de tags:\n",
      "  B-JURISPRUDENCIA → 0\n",
      "  B-LEGISLACAO → 1\n",
      "  B-LOCAL → 2\n",
      "  B-ORGANIZACAO → 3\n",
      "  B-PESSOA → 4\n",
      "  B-TEMPO → 5\n",
      "  I-JURISPRUDENCIA → 6\n",
      "  I-LEGISLACAO → 7\n",
      "  I-LOCAL → 8\n",
      "  I-ORGANIZACAO → 9\n",
      "  I-PESSOA → 10\n",
      "  I-TEMPO → 11\n",
      "  O → 12\n",
      "✅ Salvo em: ../data/parquet/LeNER-Br/dev_pt_LeNER-Br.parquet\n",
      "   Sentenças: 1176\n",
      "Mapeamento de tags:\n",
      "  B-JURISPRUDENCIA → 0\n",
      "  B-LEGISLACAO → 1\n",
      "  B-LOCAL → 2\n",
      "  B-ORGANIZACAO → 3\n",
      "  B-PESSOA → 4\n",
      "  B-TEMPO → 5\n",
      "  I-JURISPRUDENCIA → 6\n",
      "  I-LEGISLACAO → 7\n",
      "  I-LOCAL → 8\n",
      "  I-ORGANIZACAO → 9\n",
      "  I-PESSOA → 10\n",
      "  I-TEMPO → 11\n",
      "  O → 12\n",
      "✅ Salvo em: ../data/parquet/LeNER-Br/test_pt_LeNER-Br.parquet\n",
      "   Sentenças: 1389\n",
      "Mapeamento de tags:\n",
      "  B-JURISPRUDENCIA → 0\n",
      "  B-LEGISLACAO → 1\n",
      "  B-LOCAL → 2\n",
      "  B-ORGANIZACAO → 3\n",
      "  B-PESSOA → 4\n",
      "  B-TEMPO → 5\n",
      "  I-JURISPRUDENCIA → 6\n",
      "  I-LEGISLACAO → 7\n",
      "  I-LOCAL → 8\n",
      "  I-ORGANIZACAO → 9\n",
      "  I-PESSOA → 10\n",
      "  I-TEMPO → 11\n",
      "  O → 12\n",
      "✅ Salvo em: ../data/parquet/LeNER-Br/train_pt_LeNER-Br.parquet\n",
      "   Sentenças: 7827\n"
     ]
    }
   ],
   "source": [
    "for typ in list_typs:\n",
    "    tokens_list, tags_list = ler_conll(f\"../data/raw/LeNER-Br/{typ}_pt_LeNER-Br.conll\")\n",
    "    tags_ids, tag2id = tags_para_numeros(tags_list)\n",
    "    salvar_parquet(tokens_list, tags_ids, f\"../data/parquet/LeNER-Br/{typ}_pt_LeNER-Br.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e0f78ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "typs_HAREM = ['mini_HAREM', 'primeiro_HAREM', 'segundo_HAREM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4739b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meaning(text):\n",
    "    if text == 'LOCAL':\n",
    "        return 'LOC'\n",
    "    elif text == 'ORGANIZACAO':\n",
    "        return 'ORG'\n",
    "    elif text == 'PESSOA':\n",
    "        return 'PER'\n",
    "    else:\n",
    "        return 'MIST'\n",
    "    \n",
    "def list_to_entity_dict(list_items: list):\n",
    "    list_entities = []\n",
    "    for item in list_items:\n",
    "        list_entities.append((item['start_offset'], item['end_offset'], get_meaning(item['label'])))\n",
    "    \n",
    "    return list_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f6042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "for typ in typs_HAREM:\n",
    "    with open(f'../data/raw/HAREM/{typ}.json', 'r', encoding='utf-8') as arquivo:\n",
    "        data = json.load(arquivo)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.drop(['doc_id'], axis=1, inplace=True)\n",
    "    df.rename(columns={'doc_text': 'phase'}, inplace=True)\n",
    "    df['entities'] = df['entities'].apply(list_to_entity_dict)\n",
    "\n",
    "    df.to_parquet(f'../data/parquet/HAREM/{typ}.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
